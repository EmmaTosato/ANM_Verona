{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot creation",
   "id": "907ccb566498b76c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def plot_regression_clean(x, y, xlabel='Functional Disconnection', ylabel='Cognition'):\n",
    "    # Fit regressione\n",
    "    model = LinearRegression()\n",
    "    model.fit(x.reshape(-1, 1), y)\n",
    "\n",
    "    x_vals = np.linspace(min(x), max(x), 100)\n",
    "    y_vals = model.predict(x_vals.reshape(-1, 1))\n",
    "\n",
    "    # Colore rosso campionato\n",
    "    dot_color = '#6FE6FC'  # colore rosso dalla tua immagine\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Scatter\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        s=70,  # punti grandi\n",
    "        color=dot_color,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.6,\n",
    "        alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Regressione tratteggiata\n",
    "    plt.plot(x_vals, y_vals, linestyle='--', color='black', linewidth=1.5)\n",
    "\n",
    "    # Asse X e Y in basso/sinistra, pi√π spessi\n",
    "    ax = plt.gca()\n",
    "    ax.spines['bottom'].set_linewidth(1)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_edgecolor('black')\n",
    "    ax.spines['left'].set_edgecolor('black')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # Etichette assi\n",
    "    plt.xlabel(xlabel, fontsize=12, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks([])  # Rimuove i valori sull'asse X\n",
    "    ax.set_yticks([])  # Rimuove i valori sull'asse Y\n",
    "\n",
    "    # Niente griglia\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "89dec53c1ead13fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Esempio dati\n",
    "np.random.seed(1)\n",
    "x = np.random.rand(60) * 10\n",
    "y = -0.6 * x + np.random.normal(0, 2, 60) + 5\n",
    "\n",
    "plot_regression_clean(x, y)"
   ],
   "id": "fd9fb2fec2245acf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Augmentation check",
   "id": "86c212e78bccb07e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T12:54:10.995423Z",
     "start_time": "2025-04-30T12:54:10.993618Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import os"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_augmentations = 10\n",
    "subset_size = 17\n",
    "\n",
    "# Path to augmented FC maps directory\n",
    "fcmaps_augmented_dir = '/data/OLD_FCmaps_augmented'\n",
    "\n",
    "# List of 173 HCP subjects\n",
    "hcp_list_path = '/Users/emmatosato/Documents/PhD/ANM_Verona/data_utils/debugging/list_HCP.txt'\n",
    "\n",
    "# Output txt report\n",
    "path_final_report = \"/Users/emmatosato/Documents/PhD/ANM_Verona/data_utils/debugging/final_report.txt\"\n",
    "\n",
    "# Path to CSV file with missing SCA files\n",
    "path_sca_missing = \"/Users/emmatosato/Documents/PhD/ANM_Verona/data_utils/debugging/missing_SCA_files.csv\"\n",
    "\n",
    "# Summary CSV path of augmentation info\n",
    "csv_aug_path = '/Users/emmatosato/Documents/PhD/ANM_Verona/data_utils/metadata/aug_tracking.csv'"
   ],
   "id": "7003a8bccafa2a04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HCP List and Subsets",
   "id": "ea5bf2a9b0a7a71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check if the method used in augmentation.py works (note: it already has checks inside)",
   "id": "209aa33dae56a7a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Read HCP file\n",
    "with open(hcp_list_path, \"r\") as f:\n",
    "    hcp_pool = [line.strip() for line in f.readlines()]\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Generate fixed non-overlapping HCP subsets\n",
    "shuffled_hcp = random.sample(hcp_pool, n_augmentations * subset_size)\n",
    "\n",
    "hcp_subsets = [\n",
    "    shuffled_hcp[i * subset_size : (i + 1) * subset_size]\n",
    "    for i in range(n_augmentations)\n",
    "]"
   ],
   "id": "40e800dc35c89f40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that each subset has exactly 17 elements",
   "id": "64269fa076d9f986"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for idx, subset in enumerate(hcp_subsets, start=1):\n",
    "    if len(subset) != subset_size:\n",
    "        print(f\"Subset {idx} has incorrect length: {len(subset)} elements\")\n",
    "    else:\n",
    "        print(f\"Subset {idx} OK ({len(subset)} HCP)\")"
   ],
   "id": "2d82b72b387924ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check which HCPs were left out",
   "id": "a5d1273ef81fe6cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "used_hcp = set(shuffled_hcp)\n",
    "hcp_pool_set = set(hcp_pool)\n",
    "excluded_hcp = hcp_pool_set - used_hcp\n",
    "\n",
    "print(\"List of excluded HCPs:\", sorted(excluded_hcp))"
   ],
   "id": "909e19bed65c29a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check for overlaps between subsets",
   "id": "37556af58fff5726"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Flatten all subsets into a single list\n",
    "all_hcps = [hcp for subset in hcp_subsets for hcp in subset]\n",
    "\n",
    "# Compare total length vs. number of unique HCPs\n",
    "if len(all_hcps) == len(set(all_hcps)):\n",
    "    print(\"Subsets are disjoint: no overlaps.\")\n",
    "else:\n",
    "    print(\"Warning: there are overlapping HCPs between subsets.\")"
   ],
   "id": "668a91915ff648cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Augmentation Check",
   "id": "a43ab1539ccdd292"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CSV",
   "id": "eadb802ea2df1662"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aug_track = pd.read_csv(csv_aug_path)",
   "id": "7857afb66a313c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "aug_track.iloc[:5, :5]",
   "id": "56e6259075e01d15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that there are exactly 177 unique subjects",
   "id": "39f65666a9894b77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "unique_subjects = aug_track['subject'].unique()\n",
    "print(f\"Number of unique subjects: {len(unique_subjects)}\")"
   ],
   "id": "994a8e8fe51a7fca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that each subject has 10 augmentations",
   "id": "fa1d55ebc23e734d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "augment_per_subject = aug_track.groupby(\"subject\")[\"augmentation\"].count()\n",
    "subjects_missing = augment_per_subject[augment_per_subject != 10]\n",
    "\n",
    "if subjects_missing.empty:\n",
    "    print(\"All subjects have exactly 10 augmentations.\")\n",
    "else:\n",
    "    print(\"Some subjects DO NOT have 10 augmentations\")\n",
    "    print(subjects_missing)"
   ],
   "id": "78ec9fb9b87eb1dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that each augmentation has exactly 17 HCPs for all patients",
   "id": "35560748506c6cbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verify that each row in the DataFrame has exactly 17 HCPs\n",
    "aug_track[\"hcp_count\"] = aug_track[\"hcp_subset\"].apply(lambda x: len(x.split(\",\")))\n",
    "\n",
    "# Filter rows with fewer or more than 17 HCPs\n",
    "invalid_hcp_counts = aug_track[aug_track[\"hcp_count\"] != 17]\n",
    "\n",
    "# Output\n",
    "if invalid_hcp_counts.empty:\n",
    "    print(\"All augmentations have exactly 17 HCPs.\")\n",
    "else:\n",
    "    print(\"Some augmentations do NOT have 17 HCPs\")"
   ],
   "id": "b66f81fc3bd677cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Excluding inconsistent subjects, check that valid ones use the same HCPs per augmentation index across all subjects.\n",
    "That is:\n",
    "- **Sub1**\n",
    "    - *aug 1*: hcp1, hcp2, hcp3\n",
    "    - *aug 2*: hcp4, hcp5, hcp6\n",
    "    -  ...\n",
    "...\n",
    "- **Sub2**\n",
    "    - *aug 1*: hcp1, hcp2, hcp3\n",
    "    - *aug 2*: hcp4, hcp5, hcp6\n",
    "    -  ..."
   ],
   "id": "eca0fe8cd4be52c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Exclude subjects with incomplete augmentations\n",
    "valid_aug_track = aug_track[aug_track[\"hcp_count\"] == 17].copy()\n",
    "\n",
    "# For each augmentation index, compute the most frequent HCP group\n",
    "ref_hcp_by_aug = valid_aug_track.groupby(\"augmentation\")[\"hcp_subset\"].agg(lambda x: x.mode().iloc[0])\n",
    "\n",
    "# Assign expected value to each row\n",
    "valid_aug_track[\"expected_hcp_subset\"] = valid_aug_track[\"augmentation\"].map(ref_hcp_by_aug)\n",
    "\n",
    "# Find inconsistent subjects\n",
    "df_inconsistent = valid_aug_track[valid_aug_track[\"hcp_subset\"] != valid_aug_track[\"expected_hcp_subset\"]]\n",
    "\n",
    "# Final output\n",
    "if df_inconsistent.empty:\n",
    "    print(\"Same HCPs used for each augmentation across all VALID subjects.\")\n",
    "else:\n",
    "    print(\"Some augmentations have different HCPs between subjects (only among valid ones):\")\n",
    "    display(df_inconsistent[[\"subject\", \"augmentation\", \"hcp_subset\", \"expected_hcp_subset\"]].sort_values([\"augmentation\", \"subject\"]))\n"
   ],
   "id": "fda58ef4c05a2536"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Subjects with inconsistencies",
   "id": "171bfd71f8fc9e21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Subjects with inconsistencies in HCP subset:\")\n",
    "print(invalid_hcp_counts[\"subject\"].unique())"
   ],
   "id": "e7f6bf6aec1589d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example: inspect one subject with inconsistencies",
   "id": "10fbf3eec8cb9d2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter rows for a specific subject\n",
    "filtered = aug_track[aug_track[\"subject\"] == \"4_S_5005\"]"
   ],
   "id": "40a0dacc2a4d65d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "filtered[[\"subject\", \"augmentation\", \"missing_hcps\"]].sort_values(\"augmentation\").reset_index()",
   "id": "54dc4ce1270b60ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Folder",
   "id": "7d36e37a93085602"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check if augmentations were actually created",
   "id": "da379ee499fdc3a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# List all subfolders\n",
    "subfolders = [f.path for f in os.scandir(fcmaps_augmented_dir) if f.is_dir()]\n",
    "print(f\"Total subfolders (Patients): {len(subfolders)}\\n\")\n",
    "\n",
    "count_problems = 0\n",
    "# Check each subfolder\n",
    "for folder in subfolders:\n",
    "    # List only files (ignore subdirectories)\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    num_files = len(files)\n",
    "\n",
    "    # Only print if not exactly 10\n",
    "    if num_files != 10:\n",
    "        print(f\"[WARNING] {folder} --> {num_files} files (expected 10)\")\n",
    "        count_problems += 1\n",
    "\n",
    "if count_problems == 0:\n",
    "    print(\"All folders contain exactly 10 files.\")\n",
    "else:\n",
    "    print(f\"Total folders with problems: {count_problems}\")"
   ],
   "id": "e78c57ae1e796432"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check that each subject has 10 unique augmentations",
   "id": "fa6bf15dc4c0e274"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "problems = []\n",
    "\n",
    "# Loop over subject folders\n",
    "for subject_dir in os.listdir(fcmaps_augmented_dir):\n",
    "    subject_path = os.path.join(fcmaps_augmented_dir, subject_dir)\n",
    "    if os.path.isdir(subject_path):\n",
    "        files = [f for f in os.listdir(subject_path) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "        # Extract augmentation indices from filenames\n",
    "        found_aug = sorted([\n",
    "            int(f.split(\"aug\")[-1].split(\".\")[0])\n",
    "            for f in files\n",
    "            if \"aug\" in f and f.split(\"aug\")[-1].split(\".\")[0].isdigit()\n",
    "        ])\n",
    "\n",
    "        expected = list(range(1, 11))\n",
    "        if found_aug != expected:\n",
    "            problems.append((subject_dir, found_aug))\n",
    "\n",
    "# Final report\n",
    "if problems:\n",
    "    print(\"Problems found in the following subjects:\")\n",
    "    for subj, augs in problems:\n",
    "        print(f\"[PROBLEM] {subj} has augmentations: {augs}\")\n",
    "else:\n",
    "    print(\"All folders contain augmentations from 1 to 10 correctly.\")\n"
   ],
   "id": "99581328dd2b7734"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing HCPs and SCA files missing",
   "id": "bc4376f8eda88c38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "HCP missing as SCA files in the dataset (Lorenzo folder) and here",
   "id": "1a685d6ade8ee691"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSVs\n",
    "sca_missing_df = pd.read_csv(path_sca_missing)\n",
    "aug_track = pd.read_csv(csv_aug_path)\n",
    "\n",
    "# Variables\n",
    "n_total_hcp = 173\n",
    "results = []\n",
    "unexpected_missing_total = set()\n",
    "\n",
    "# Loop through subjects\n",
    "for subject in sca_missing_df[\"subject\"].unique():\n",
    "    # From missing_SCA_files\n",
    "    row_sca = sca_missing_df[sca_missing_df[\"subject\"] == subject]\n",
    "    sca_missing = set(row_sca.iloc[0][\"SCA_files_missing\"].split(\",\"))\n",
    "    count_missing = len(sca_missing)\n",
    "\n",
    "    # From aug_tracking\n",
    "    sub_aug = aug_track[aug_track[\"subject\"] == subject]\n",
    "    expected_hcp = set()\n",
    "    for row in sub_aug[\"missing_hcps\"]:\n",
    "        hcp_ids = row.strip().strip('\"').split(\",\")\n",
    "        expected_hcp.update(hcp_ids)\n",
    "\n",
    "    # Intersections\n",
    "    expected_and_missing = sca_missing.intersection(expected_hcp)\n",
    "    unexpected_and_missing = sca_missing - expected_hcp\n",
    "    unexpected_missing_total.update(unexpected_and_missing)\n",
    "\n",
    "    # Subject output\n",
    "    results.append(f\"Soggetto {subject}:\\n\")\n",
    "    results.append(f\"- Missing SCA files: {count_missing}\\n\")\n",
    "    results.append(f\"- Used SCA files:  {n_total_hcp - count_missing}\\n\")\n",
    "    results.append(f\"- File attesi nell'augmentation e mancanti come SCA: {', '.join(sorted(expected_and_missing))}\\n\")\n",
    "    results.append(f\"- File NON attesi nell'augmentation e mancanti come SCA: {', '.join(sorted(unexpected_and_missing))}\\n\\n\")\n",
    "\n",
    "# Final section\n",
    "results.append(\"Unique list of NON expected SCA-missing files:\\n\")\n",
    "results.append(f\"{', '.join(sorted(unexpected_missing_total))}\\n\")\n",
    "\n",
    "if unexpected_missing_total == excluded_hcp:\n",
    "    results.append(f\"----> The NON expected and missing SCA files match those excluded from augmentation.\\n\")\n",
    "\n",
    "# Write report to file\n",
    "with open(path_final_report, \"w\") as f:\n",
    "    f.writelines(results)\n"
   ],
   "id": "ccb3ab6b41d6615e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:34:49.367158Z",
     "start_time": "2025-06-23T16:34:49.347077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "mam = pd.read_excel(\"/Users/emmatosato/Downloads/5AS calcolo_valutazione_esame.xlsx\", header=1)"
   ],
   "id": "e3662930c75ee367",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/neuro/lib/python3.10/site-packages/openpyxl/worksheet/_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:34:49.838076Z",
     "start_time": "2025-06-23T16:34:49.820555Z"
    }
   },
   "cell_type": "code",
   "source": "mam",
   "id": "e8d28c34f3ac0d3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0  Numero progressivo         Cognome e Nome  Media  Credito  \\\n",
       "0          NaN                   1        AMBROSI MATTEO     9.5     39.0   \n",
       "1          NaN                   2             BOJA LIVIA    7.2     30.0   \n",
       "2          NaN                   3          CIONCA TABITA    8.7     36.0   \n",
       "3          NaN                   4       COSTANTINI IRENE    8.5     36.0   \n",
       "4          NaN                   5      ED DAOUDI YASMINE    7.9     32.0   \n",
       "5          NaN                   6          GOBBI ALBERTO    8.5     37.0   \n",
       "6          NaN                   7          GUZZO GIORGIA    9.1     39.0   \n",
       "7          NaN                   8        ISALBERTI MARTA    8.0     34.0   \n",
       "8          NaN                   9            LOVATO SARA    8.5     37.0   \n",
       "9          NaN                  10    MARANGONI FEDERICO     7.8     33.0   \n",
       "10         NaN                  11        MARCOLONGO ANNA    8.0     34.0   \n",
       "11         NaN                  12         MASTROENI LARA    8.7     36.0   \n",
       "12         NaN                  13       MERLIN GIANMARCO    8.2     34.0   \n",
       "13         NaN                  14         MERLIN VANESSA    8.4     35.0   \n",
       "14         NaN                  15       MOLDOVAN MELISSA    7.6     31.0   \n",
       "15         NaN                  16           PESENTE ELIA    9.0     38.0   \n",
       "16         NaN                  17  POLTRONIERI FRANCESCO    8.8     36.0   \n",
       "17         NaN                  18         PRANDINI ALICE    8.6     38.0   \n",
       "18         NaN                  19          RIGONI ANDREA    9.1     39.0   \n",
       "19         NaN                  20          ROSSINI ELISA    9.4     40.0   \n",
       "20         NaN                  21       TACCHINI FILIPPO    8.3     36.0   \n",
       "21         NaN                  22     TAVELLIN VITTORIA     8.5     36.0   \n",
       "22         NaN                  23             TONEL SARA    8.1     34.0   \n",
       "23         NaN                  24      TORRESANI FILIPPO    9.5     40.0   \n",
       "24         NaN                  25       VEGGIARI LORENZO    8.6     36.0   \n",
       "25         NaN                  26       ZOVADELLI GIULIA    8.7     37.0   \n",
       "26         NaN                  27                    NaN    NaN      NaN   \n",
       "27         NaN                  28                    NaN    NaN      NaN   \n",
       "28         NaN                  29                    NaN    NaN      NaN   \n",
       "29         NaN                  30                    NaN    NaN      NaN   \n",
       "\n",
       "    Prima prova  Seconda prova  Colloquio  Totale prove  \\\n",
       "0          18.0           20.0        NaN          38.0   \n",
       "1          13.0            8.0        NaN          21.0   \n",
       "2          10.0           18.0        NaN          28.0   \n",
       "3          11.0           19.0        NaN          30.0   \n",
       "4          10.0           14.0        NaN          24.0   \n",
       "5          10.0           16.0        NaN          26.0   \n",
       "6          18.0           19.0        NaN          37.0   \n",
       "7          17.0           10.0        NaN          27.0   \n",
       "8          14.0           18.0        NaN          32.0   \n",
       "9          12.0           11.0        NaN          23.0   \n",
       "10         16.0           14.0        NaN          30.0   \n",
       "11         14.0           14.0        NaN          28.0   \n",
       "12         13.0           12.0        NaN          25.0   \n",
       "13         11.0           17.0        NaN          28.0   \n",
       "14         11.0           14.0        NaN          25.0   \n",
       "15         14.0           19.0        NaN          33.0   \n",
       "16         14.0           19.0        NaN          33.0   \n",
       "17         18.0           18.0        NaN          36.0   \n",
       "18         20.0           19.0        NaN          39.0   \n",
       "19         16.0           20.0        NaN          36.0   \n",
       "20         12.0           13.0        NaN          25.0   \n",
       "21         15.0           18.0        NaN          33.0   \n",
       "22         12.0           15.0        NaN          27.0   \n",
       "23         19.0           20.0        NaN          39.0   \n",
       "24         12.0           14.0        NaN          26.0   \n",
       "25          9.0           17.0        NaN          26.0   \n",
       "26          NaN            NaN        NaN           NaN   \n",
       "27          NaN            NaN        NaN           NaN   \n",
       "28          NaN            NaN        NaN           NaN   \n",
       "29          NaN            NaN        NaN           NaN   \n",
       "\n",
       "    Totale crediti + scritti + colloquio Bonus attribuibile?  BONUS  \\\n",
       "0                                   77.0                  No    0.0   \n",
       "1                                   51.0                  No    0.0   \n",
       "2                                   64.0                  No    0.0   \n",
       "3                                   66.0                  No    0.0   \n",
       "4                                   56.0                  No    0.0   \n",
       "5                                   63.0                  No    0.0   \n",
       "6                                   76.0                  No    0.0   \n",
       "7                                   61.0                  No    0.0   \n",
       "8                                   69.0                  No    0.0   \n",
       "9                                   56.0                  No    0.0   \n",
       "10                                  64.0                  No    0.0   \n",
       "11                                  64.0                  No    0.0   \n",
       "12                                  59.0                  No    0.0   \n",
       "13                                  63.0                  No    0.0   \n",
       "14                                  56.0                  No    0.0   \n",
       "15                                  71.0                  No    0.0   \n",
       "16                                  69.0                  No    0.0   \n",
       "17                                  74.0                  No    0.0   \n",
       "18                                  78.0                  No    0.0   \n",
       "19                                  76.0                  No    0.0   \n",
       "20                                  61.0                  No    0.0   \n",
       "21                                  69.0                  No    0.0   \n",
       "22                                  61.0                  No    0.0   \n",
       "23                                  79.0                  No    0.0   \n",
       "24                                  62.0                  No    0.0   \n",
       "25                                  63.0                  No    0.0   \n",
       "26                                   NaN                 NaN    NaN   \n",
       "27                                   NaN                 NaN    NaN   \n",
       "28                                   NaN                 NaN    NaN   \n",
       "29                                   NaN                 NaN    NaN   \n",
       "\n",
       "    Voto finale LODE ASSEGNABILE?  \n",
       "0          77.0                No  \n",
       "1          51.0                No  \n",
       "2          64.0                No  \n",
       "3          66.0                No  \n",
       "4          56.0                No  \n",
       "5          63.0                No  \n",
       "6          76.0                No  \n",
       "7          61.0                No  \n",
       "8          69.0                No  \n",
       "9          56.0                No  \n",
       "10         64.0                No  \n",
       "11         64.0                No  \n",
       "12         59.0                No  \n",
       "13         63.0                No  \n",
       "14         56.0                No  \n",
       "15         71.0                No  \n",
       "16         69.0                No  \n",
       "17         74.0                No  \n",
       "18         78.0                No  \n",
       "19         76.0                No  \n",
       "20         61.0                No  \n",
       "21         69.0                No  \n",
       "22         61.0                No  \n",
       "23         79.0                No  \n",
       "24         62.0                No  \n",
       "25         63.0                No  \n",
       "26          NaN               NaN  \n",
       "27          NaN               NaN  \n",
       "28          NaN               NaN  \n",
       "29          NaN               NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Numero progressivo</th>\n",
       "      <th>Cognome e Nome</th>\n",
       "      <th>Media</th>\n",
       "      <th>Credito</th>\n",
       "      <th>Prima prova</th>\n",
       "      <th>Seconda prova</th>\n",
       "      <th>Colloquio</th>\n",
       "      <th>Totale prove</th>\n",
       "      <th>Totale crediti + scritti + colloquio</th>\n",
       "      <th>Bonus attribuibile?</th>\n",
       "      <th>BONUS</th>\n",
       "      <th>Voto finale</th>\n",
       "      <th>LODE ASSEGNABILE?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>AMBROSI MATTEO</td>\n",
       "      <td>9.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>BOJA LIVIA</td>\n",
       "      <td>7.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>CIONCA TABITA</td>\n",
       "      <td>8.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COSTANTINI IRENE</td>\n",
       "      <td>8.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>ED DAOUDI YASMINE</td>\n",
       "      <td>7.9</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>GOBBI ALBERTO</td>\n",
       "      <td>8.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>GUZZO GIORGIA</td>\n",
       "      <td>9.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>ISALBERTI MARTA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>LOVATO SARA</td>\n",
       "      <td>8.5</td>\n",
       "      <td>37.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>MARANGONI FEDERICO</td>\n",
       "      <td>7.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>MARCOLONGO ANNA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>MASTROENI LARA</td>\n",
       "      <td>8.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>MERLIN GIANMARCO</td>\n",
       "      <td>8.2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>MERLIN VANESSA</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>MOLDOVAN MELISSA</td>\n",
       "      <td>7.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>PESENTE ELIA</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>POLTRONIERI FRANCESCO</td>\n",
       "      <td>8.8</td>\n",
       "      <td>36.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>PRANDINI ALICE</td>\n",
       "      <td>8.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>RIGONI ANDREA</td>\n",
       "      <td>9.1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>ROSSINI ELISA</td>\n",
       "      <td>9.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>TACCHINI FILIPPO</td>\n",
       "      <td>8.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>TAVELLIN VITTORIA</td>\n",
       "      <td>8.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>TONEL SARA</td>\n",
       "      <td>8.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>TORRESANI FILIPPO</td>\n",
       "      <td>9.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>VEGGIARI LORENZO</td>\n",
       "      <td>8.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>ZOVADELLI GIULIA</td>\n",
       "      <td>8.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T16:36:53.068171Z",
     "start_time": "2025-06-23T16:36:53.064335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "media = round(mam['Media'].mean(),2)\n",
    "media1 = round(mam['Prima prova'].mean(),2)\n",
    "media2 = round(mam['Seconda prova'].mean(),2)\n",
    "\n",
    "print(f\"Media della media:\", media)\n",
    "print(f\"Media della Prima prova:\", media1)\n",
    "print(f\"Media della Seconda prova:\", media2)"
   ],
   "id": "17f9765b790f2e84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media della media: 8.51\n",
      "Media della Prima prova: 13.81\n",
      "Media della Seconda prova: 16.0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "12d405040b5389c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
