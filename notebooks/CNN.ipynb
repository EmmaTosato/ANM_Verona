{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11601721,"sourceType":"datasetVersion","datasetId":7276265},{"sourceId":11602172,"sourceType":"datasetVersion","datasetId":7276616},{"sourceId":11602206,"sourceType":"datasetVersion","datasetId":7276639}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Utils","metadata":{"_uuid":"14955c6c-b6b7-4cc3-b48a-18780436718f","_cell_guid":"a8170246-22b6-42a9-abd6-68c2979d5f8a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.video import r3d_18\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\nfrom sklearn.metrics import precision_recall_curve, roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.model_selection import StratifiedKFold\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"6308cabb-bcd2-4137-ad37-379413164088","_cell_guid":"d7a8972d-7eb1-4b76-9fc5-3ee8e93b1422","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.506594Z","iopub.execute_input":"2025-05-06T17:07:31.507115Z","iopub.status.idle":"2025-05-06T17:07:31.512046Z","shell.execute_reply.started":"2025-05-06T17:07:31.507092Z","shell.execute_reply":"2025-05-06T17:07:31.511250Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Paths\npath_labels = '/kaggle/input/fcmaps-metadata/labels.csv'\npath_fcmaps = '/kaggle/input/fcmaps-processed'                   \npath_fcmaps_augmented = '/kaggle/input/fcmaps-augmented-processed/FCmaps_augmented_processed'\n\n# Load labels\ndf_labels = pd.read_csv(path_labels)\n\n# Temporary:\nto_exclude = ['3_S_5003', '4_S_5003', '4_S_5005', '4_S_5007', '4_S_5008']\ndf_labels = df_labels[~df_labels['ID'].isin(to_exclude)].reset_index(drop=True)","metadata":{"_uuid":"98413937-5d05-451e-bd82-db2568a79065","_cell_guid":"4dca98c7-47ba-4b83-b5a4-2265860865de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.550207Z","iopub.execute_input":"2025-05-06T17:07:31.550631Z","iopub.status.idle":"2025-05-06T17:07:31.570656Z","shell.execute_reply.started":"2025-05-06T17:07:31.550614Z","shell.execute_reply":"2025-05-06T17:07:31.570106Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# PARAMETERS DICTIONARY\n\nparams = {\n    'batch_size': 8,\n    'epochs': 20,\n    'lr': 1e-3,\n    'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    'task': 'classification', \n    'n_folds': 10,  \n    'network': 'resnet',  # 'resnet' or 'simplecnn'\n    'group1': 'ADNI',\n    'group2': 'PSP',\n    'test_size': 0.2,\n    'val_size': 0.2,\n    'label_column': 'Group',\n    'use_cross_val': True,\n    'checkpoints_dir':\"/kaggle/working/checkpoints\"\n}\n\n# Loss function and number of classes\nif params['task'] == 'classification':\n    params['criterion'] = nn.CrossEntropyLoss()\n    params['n_classes'] = 2\nelse:\n    params['criterion'] = nn.MSELoss()\n    params['n_classes'] = 1\n\n\n# Output directory for checkpoints\nos.makedirs(params['checkpoints_dir'], exist_ok=True)","metadata":{"_uuid":"893c4830-dc91-4a34-a5c4-26859088ad91","_cell_guid":"4941eb5c-bdab-4fb6-a42a-3200f9077521","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:43:17.607575Z","iopub.execute_input":"2025-05-06T17:43:17.607940Z","iopub.status.idle":"2025-05-06T17:43:17.613167Z","shell.execute_reply.started":"2025-05-06T17:43:17.607917Z","shell.execute_reply":"2025-05-06T17:43:17.612494Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# Dataset","metadata":{"_uuid":"f20ef8dd-c556-4e79-a1f3-5209b30013c3","_cell_guid":"80218115-2e61-4df0-b18a-00ce132993fd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class FCDataset(Dataset):\n    def __init__(self, data_dir, df_labels, label_column, task, transform=None):       \n        self.data_dir = data_dir\n        self.df_labels = df_labels.reset_index(drop=True)\n        self.label_column = label_column\n        self.task = task\n        self.transform = transform\n    \n        # Dictionary for mapping strings to indices if labels are not numbers\n        if not pd.api.types.is_numeric_dtype(self.df_labels[self.label_column]):\n            unique_labels = sorted(self.df_labels[self.label_column].unique())\n            self.label_mapping = {label: i for i, label in enumerate(unique_labels)}\n        else:\n            self.label_mapping = None\n            \n        self.samples = []\n\n        # Loop over each row of the dataframe\n        for _, row in self.df_labels.iterrows():\n            subj_id = row['ID']\n            \n            if self.task == 'classification':\n                # Classification: map the labels\n                label = self.label_mapping[row[self.label_column]]\n            \n            else:  \n                # Regression: convert to float\n                label = float(row[self.label_column])\n\n            # Reconstruct the file paths \n            file_path = os.path.join(data_dir, f\"{subj_id}.processed.npy\")\n            if os.path.exists(file_path):\n                self.samples.append((file_path, label))\n            else:\n                print(f\"Missing file: {file_path}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        file_path, label = self.samples[idx]\n        \n        # Load and reshape the volume: (1, 91, 109, 91)\n        volume = np.load(file_path)\n        volume = np.expand_dims(volume, axis=0)  \n\n        # Covert volume into a tensor\n        x = torch.tensor(volume, dtype=torch.float32)\n\n        # Convert the label into a tensor\n        if self.task == 'classification':\n            y = torch.tensor(label, dtype=torch.long)\n        else: \n            y = torch.tensor(label, dtype=torch.float32)\n\n        if self.transform:\n            x = self.transform(x)\n\n        return x, y","metadata":{"_uuid":"2e930299-ad48-4722-866f-adee975b09ee","_cell_guid":"1378c44f-1174-41ef-8068-61a0a8406200","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.658603Z","iopub.execute_input":"2025-05-06T17:07:31.658853Z","iopub.status.idle":"2025-05-06T17:07:31.671343Z","shell.execute_reply.started":"2025-05-06T17:07:31.658835Z","shell.execute_reply":"2025-05-06T17:07:31.670619Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class AugmentedFCDataset(Dataset):\n    def __init__(self, data_dir, df_labels, label_column, task, transform=None):\n        \n        self.data_dir = data_dir\n        self.df_labels = df_labels.reset_index(drop=True)\n        self.label_column = label_column\n        self.task = task\n        self.transform = transform\n\n        # Mapping\n        if not pd.api.types.is_numeric_dtype(self.df_labels[self.label_column]):\n            unique_labels = sorted(self.df_labels[self.label_column].unique())\n            self.label_mapping = {label: i for i, label in enumerate(unique_labels)}\n        else:\n            self.label_mapping = None\n            \n        self.samples = []\n\n        for _, row in self.df_labels.iterrows():\n            subj_id = row['ID']\n\n            if self.task == 'classification':\n                label = self.label_mapping[row[self.label_column]]\n            else:\n                label = float(row[self.label_column])\n\n            # Loop over each subject folder and list each augmentation\n            subject_folder = os.path.join(data_dir, subj_id)\n            if os.path.isdir(subject_folder):\n                for file in os.listdir(subject_folder):\n                    if file.endswith('.npy'):\n                        file_path = os.path.join(subject_folder, file)\n                        self.samples.append((file_path, label))\n            else:\n                print(f\"Warning: missing augmented folder for subject {subj_id}\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        file_path, label = self.samples[idx]\n\n        # Load and reshape the volume: (1, 91, 109, 91)\n        volume = np.load(file_path)\n        volume = np.expand_dims(volume, axis=0)\n\n        x = torch.tensor(volume, dtype=torch.float32)\n\n        if self.task == 'classification':\n            y = torch.tensor(label, dtype=torch.long)\n        else:\n            y = torch.tensor(label, dtype=torch.float32)\n\n        if self.transform:\n            x = self.transform(x)\n\n        return x, y","metadata":{"_uuid":"8e946be7-1c81-475e-9ba0-e13f2656066a","_cell_guid":"504d0cf4-617c-41d6-bcc5-50726ac5dec7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.672069Z","iopub.execute_input":"2025-05-06T17:07:31.672542Z","iopub.status.idle":"2025-05-06T17:07:31.688481Z","shell.execute_reply.started":"2025-05-06T17:07:31.672518Z","shell.execute_reply":"2025-05-06T17:07:31.687740Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# CNN Models","metadata":{"_uuid":"e2170dc4-5a1e-428b-9ca1-7467c67dad06","_cell_guid":"5734aab1-e999-4373-a84d-5d9a0debe8a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Network","metadata":{"_uuid":"132064ae-b4bf-49ea-89c0-e079dbfa968c","_cell_guid":"3825f1bd-e30e-4349-8797-8a4b390396e7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class SimpleCNN3D(nn.Module):\n    def __init__(self, n_classes):\n        super(SimpleCNN3D, self).__init__()\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm3d(16)\n        self.pool1 = nn.MaxPool3d(2)\n\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm3d(32)\n        self.pool2 = nn.MaxPool3d(2)\n\n        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm3d(64)\n        self.pool3 = nn.AdaptiveAvgPool3d(1)\n\n        self.dropout = nn.Dropout(p=0.4)\n        self.fc = nn.Linear(64, n_classes)\n\n    def forward(self, x):\n        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)\n        return self.fc(x)\n\n\nclass ResNet3D(nn.Module):\n    def __init__(self, n_classes):\n        super(ResNet3D, self).__init__()\n        self.model = r3d_18(weights=None)\n        self.model.stem[0] = nn.Conv3d(1, 64, kernel_size=(3,7,7), stride=(1,2,2), padding=(1,3,3), bias=False)\n        self.model.fc = nn.Linear(self.model.fc.in_features, n_classes)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"0d73c0ce-5bc5-4e2e-86a7-c110763eb8f2","_cell_guid":"be1e4ebc-f2f6-4800-8b1f-5be8bb947bcb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.689711Z","iopub.execute_input":"2025-05-06T17:07:31.689905Z","iopub.status.idle":"2025-05-06T17:07:31.707299Z","shell.execute_reply.started":"2025-05-06T17:07:31.689890Z","shell.execute_reply":"2025-05-06T17:07:31.706668Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Data","metadata":{"_uuid":"b2db1b9d-5367-4530-b420-09d3ae32c3ad","_cell_guid":"6dc0c921-38e3-4bb4-8a11-d606111f78f0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Load some files for example","metadata":{"_uuid":"a4c95302-d2c2-4a14-a130-4330512df1a5","_cell_guid":"50fc3f92-cb3b-4f27-9efd-57e41c7b8567","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"img3D = np.load('/kaggle/input/fcmaps-processed/002_S_4654.processed.npy')\n\nprint(img3D.shape)\nprint(img3D.dtype)","metadata":{"_uuid":"1d952ddc-8906-49db-9c80-e6eca7895738","_cell_guid":"fd80399b-7d7f-462c-aece-e81719701c49","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:31.751341Z","iopub.execute_input":"2025-05-06T17:07:31.751583Z","iopub.status.idle":"2025-05-06T17:07:31.779477Z","shell.execute_reply.started":"2025-05-06T17:07:31.751558Z","shell.execute_reply":"2025-05-06T17:07:31.778962Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"(91, 109, 91)\nfloat32\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Pairwise classification","metadata":{"_uuid":"c5cee6ea-d167-4fc9-98c3-c56e6c7b3638","_cell_guid":"890356bb-fcff-4b08-a89f-0da28c1d41cb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"- ADNI + CBS = 116 \n- CBS + PSP = 105 \n- ADNI + PSP = 133","metadata":{"_uuid":"5f7ba586-b2cb-42ea-9ff8-01e5d70b020a","_cell_guid":"55084900-45ce-4c28-9c1c-f7cf5dbb836c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"df_pair = df_labels[df_labels['Group'].isin([params['group1'], params['group2']])].reset_index(drop=True)","metadata":{"_uuid":"3ff3adfd-f5d3-4f1f-b904-b38a5c302f35","_cell_guid":"e326315d-0669-4462-856a-c9a76ae56b9b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:38.698968Z","iopub.execute_input":"2025-05-06T17:07:38.699491Z","iopub.status.idle":"2025-05-06T17:07:38.704604Z","shell.execute_reply.started":"2025-05-06T17:07:38.699469Z","shell.execute_reply":"2025-05-06T17:07:38.703648Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(df_pair.shape)\nprint(\"\\nSubjects per group:\")\nprint(df_pair['Group'].value_counts())","metadata":{"_uuid":"7c45ab18-d0c0-47e2-9bed-ba420f6fe935","_cell_guid":"ef467a53-ac3c-4f14-b4d6-56450d67d893","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:07:58.396494Z","iopub.execute_input":"2025-05-06T17:07:58.396769Z","iopub.status.idle":"2025-05-06T17:07:58.403156Z","shell.execute_reply.started":"2025-05-06T17:07:58.396749Z","shell.execute_reply":"2025-05-06T17:07:58.402395Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"(129, 5)\n\nSubjects per group:\nGroup\nADNI    72\nPSP     57\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## Splitting","metadata":{"_uuid":"33591bb2-3114-4397-bdaa-d83ee4376915","_cell_guid":"3e744a5d-abe0-4fdf-bac1-30af3c7b9c3b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# ----------- SPLIT TRAIN/TEST ------------\nsubjects = df_pair['ID'].values\nlabels = df_pair[params['label_column']].values\n\ntrain_subj, test_subj = train_test_split(\n    subjects,\n    stratify=labels,\n    test_size=params['test_size'],\n    random_state=42\n)\n\ntrain_df = df_pair[df_pair['ID'].isin(train_subj)].reset_index(drop=True)\ndf_test = df_pair[df_pair['ID'].isin(test_subj)].reset_index(drop=True)\n\n\n# ----------- SPLIT TRAIN/VALIDATION  ------------\nif params['use_cross_val']:\n    df_train = train_df\n    print(\"Cross-validation selected: Validation sets will be created inside each fold.\")\nelse:\n    subjects_train = train_df['ID'].values\n    labels_train = train_df[params['label_column']].values\n\n    train_subj, val_subj = train_test_split(\n        subjects_train,\n        stratify=labels_train,\n        test_size=params['val_size'],\n        random_state=42\n    )\n\n    df_train = train_df[train_df['ID'].isin(train_subj)].reset_index(drop=True)\n    df_val = train_df[train_df['ID'].isin(val_subj)].reset_index(drop=True)","metadata":{"_uuid":"5552591d-88aa-444c-8fd4-daf5ff5bb765","_cell_guid":"d85dee23-fce5-42e8-b48f-b602ed3a0dea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-06T17:11:45.098859Z","iopub.execute_input":"2025-05-06T17:11:45.099121Z","iopub.status.idle":"2025-05-06T17:11:45.108995Z","shell.execute_reply.started":"2025-05-06T17:11:45.099100Z","shell.execute_reply":"2025-05-06T17:11:45.108295Z"}},"outputs":[{"name":"stdout","text":"Cross-validation selected: Validation sets will be created inside each fold.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"Check balance","metadata":{"_uuid":"4412081a-7d85-4aea-aabc-724c93f91af8","_cell_guid":"1503504a-edb1-4c57-b8bb-621749f64b98","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"Train set label distribution:\")\nprint(\"Total size of the training set: \", df_train.shape[0])\nprint(df_train['Group'].value_counts())\n\nif not params['use_cross_val']:\n    print(\"\\nValidation set label distribution:\")\n    print(\"Total size of the validation set: \", df_val.shape[0])\n    print(df_val['Group'].value_counts())\n\nprint(\"\\nTest set label distribution:\")\nprint(\"Total size of the testing set: \", df_test.shape[0])\nprint(df_test['Group'].value_counts())","metadata":{"_uuid":"6a932c5e-6f9d-4dcb-bcad-523b4d7b4fe6","_cell_guid":"846692b8-ee6d-47b8-a44b-5d8c8cac1345","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:11:47.025786Z","iopub.execute_input":"2025-05-06T17:11:47.026054Z","iopub.status.idle":"2025-05-06T17:11:47.033318Z","shell.execute_reply.started":"2025-05-06T17:11:47.026034Z","shell.execute_reply":"2025-05-06T17:11:47.032439Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Train set label distribution:\nTotal size of the training set:  103\nGroup\nADNI    57\nPSP     46\nName: count, dtype: int64\n\nTest set label distribution:\nTotal size of the testing set:  26\nGroup\nADNI    15\nPSP     11\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"Example of augmentation","metadata":{"_uuid":"449306b6-8015-432d-b600-91259c26aac8","_cell_guid":"495eff62-9280-47d4-af0b-51174ba4c276","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_dataset = AugmentedFCDataset(path_fcmaps_augmented, train_df, params['label_column'], params['task'])","metadata":{"_uuid":"58e1e2e1-4abe-4a50-bce0-e5882eb93445","_cell_guid":"601e67e2-851f-4e60-b451-056fbec4d50e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-06T17:12:25.713506Z","iopub.execute_input":"2025-05-06T17:12:25.714088Z","iopub.status.idle":"2025-05-06T17:12:27.775599Z","shell.execute_reply.started":"2025-05-06T17:12:25.714066Z","shell.execute_reply":"2025-05-06T17:12:27.774833Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(\"Shape before augmentation: \", train_df.shape )\nprint(\"Shape after augmentation: \", len(train_dataset) )","metadata":{"_uuid":"fb591b5c-7e0f-4306-9850-d83f82a7defb","_cell_guid":"a6d729c8-ed47-4ec3-a7ab-9eb73cd4ddb3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-05T08:13:51.808348Z","iopub.execute_input":"2025-05-05T08:13:51.809037Z","iopub.status.idle":"2025-05-05T08:13:51.812879Z","shell.execute_reply.started":"2025-05-05T08:13:51.809014Z","shell.execute_reply":"2025-05-05T08:13:51.812219Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and validation","metadata":{"_uuid":"b7e5c58b-7649-48ff-8422-0594a22be558","_cell_guid":"66554c95-6c75-4d71-a19b-d3fb70e27c77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Train, Validaiton and Evaluation Loop","metadata":{}},{"cell_type":"markdown","source":"Training function","metadata":{}},{"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer, device):\n    # Enable training mode\n    model.train()\n    running_loss = 0.0\n\n    for x_batch, y_batch in train_loader:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n        # Reset gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(x_batch)\n\n        # Compute loss\n        loss = criterion(outputs, y_batch)\n\n        # Backpropagation\n        loss.backward()\n\n        # Update weights\n        optimizer.step()\n\n        running_loss += loss.item() * x_batch.size(0)\n\n    train_loss = running_loss / len(train_loader.dataset)\n    return train_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Validation function","metadata":{}},{"cell_type":"code","source":"def validate(val_loader, model, criterion, device, task):\n    # Set model to evaluation mode\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n\n    # Disable gradient computation\n    with torch.no_grad():\n        for x_val, y_val in val_loader:\n            x_val, y_val = x_val.to(device), y_val.to(device)\n            outputs = model(x_val)\n            loss = criterion(outputs, y_val)\n            running_loss += loss.item() * x_val.size(0)\n            \n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == y_val).sum().item()\n\n    val_loss = running_loss / len(val_loader.dataset)\n    val_accuracy = correct / len(val_loader.dataset)\n    return val_loss, val_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Evaluation function (to get predictions)","metadata":{}},{"cell_type":"code","source":"def evaluate(model, loader, task, device):\n    model.eval()\n    true_labels, pred_labels = [], []\n\n    # Disable gradient computation\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n\n            # Convert output to prediction\n            if task == 'classification':\n                preds = torch.argmax(outputs, dim=1)  \n            else:\n                preds = outputs.squeeze()  \n\n            # Store true and predicted values\n            true_labels.extend(y.cpu().numpy())\n            pred_labels.extend(preds.cpu().numpy())\n\n    return np.array(true_labels), np.array(pred_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Potting","metadata":{}},{"cell_type":"code","source":"def plot_losses_and_accuracy(train_losses, val_losses, val_accuracies):\n    \"\"\"\n    Plot Train Loss, Validation Loss and Validation Accuracy over epochs.\n    \"\"\"\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss', marker='o', color='blue')\n    plt.plot(val_losses, label='Validation Loss', marker='s', color='orange')\n    plt.plot(val_accuracies, label='Validation Accuracy', marker='^', color='green')\n    plt.xlabel('Epoch')\n    plt.ylabel('Value')\n    plt.title('Training Loss, Validation Loss and Validation Accuracy')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\ndef plot_losses_only(train_losses, val_losses):\n    \"\"\"\n    Plot Train and Validation Loss only.\n    \"\"\"\n    plt.figure(figsize=(8, 5))\n    plt.plot(train_losses, label='Train Loss', marker='o', color='blue')\n    plt.plot(val_losses, label='Validation Loss', marker='s', color='orange')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training without cross validation","metadata":{}},{"cell_type":"code","source":"def train_validate_model(df_train, df_val, params):\n    # Create Datasets\n    train_dataset = AugmentedFCDataset(path_fcmaps_augmented, df_train, params['label_column'], params['task'])\n    val_dataset = FCDataset(path_fcmaps, df_val, params['label_column'], params['task'])\n\n    # Create DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n    \n    # Model\n    if params['network'] == 'resnet':\n        model = ResNet3D(n_classes=params['n_classes']).to(params['device'])\n    elif params['network'] == 'simplecnn':\n        model = SimpleCNN3D(n_classes=params['n_classes']).to(params['device'])\n    else:\n        raise ValueError(\"Invalid network specified in params\")\n        \n    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n    criterion = params['criterion']\n\n    # Variables\n    train_losses = []\n    val_losses = []\n    val_accuracies = []\n\n    best_accuracy = -float('inf')\n    best_epoch = -1\n    best_model_path = None\n\n    # Loop over epochs\n    for epoch in range(params['epochs']):\n        train_loss = train(train_loader, model, criterion, optimizer, params['device'])\n        val_loss, val_accuracy = validate(val_loader, model, criterion, params['device'], params['task'])\n\n        print(f\"Epoch {epoch+1}/{params['epochs']} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        # Save best model with group names in filename\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            best_epoch = epoch + 1  \n            best_model_path = os.path.join(checkpoint_dir,f'best_model_{params[\"group1\"]}_vs_{params[\"group2\"]}_epoch{best_epoch}.pt')\n            torch.save(model.state_dict(), best_model_path)\n\n    print(\"\\nTraining completed.\")\n    print(f\"Best model saved at epoch {best_epoch} with validation accuracy: {best_accuracy:.4f}\")\n\n    # Plot\n    plot_losses_and_accuracy(train_losses, val_losses, val_accuracies)\n    plot_losses_only(train_losses, val_losses)\n\n    return best_model_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cross-Validation","metadata":{}},{"cell_type":"code","source":"def train_model_kfold(df_train, path_fcmaps_augmented, path_fcmaps, params):\n    # For k-fold cross-validation\n    skf = StratifiedKFold(n_splits=params['n_folds'], shuffle=True, random_state=42)\n    \n    # Subjects and correspondent labels \n    subjects = df_train['ID'].values\n    labels = df_train[params['label_column']].values\n    \n    all_train_losses = []\n    all_val_losses = []\n    all_val_accuracies = []\n    best_model_paths = []\n\n    # Loop over the k-fold\n   for fold, (train_idx, val_idx) in enumerate(skf.split(subjects, labels)):\n        print(f\"\\n--- Fold {fold+1}/{params['n_folds']} ---\")\n\n        # Subjects for the current fold\n        df_train_fold = df_train[df_train['ID'].isin(subjects[train_idx])].reset_index(drop=True)\n        df_val_fold = df_train[df_train['ID'].isin(subjects[val_idx])].reset_index(drop=True)\n    \n        # Create Datasets\n        train_dataset = AugmentedFCDataset(path_fcmaps_augmented, df_train_fold, params['label_column'], params['task'])\n        val_dataset = FCDataset(path_fcmaps, df_val_fold, params['label_column'], params['task'])\n\n        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n        \n        # Create the model and optimizer \n        if params['network'] == 'resnet':\n            model = ResNet3D(n_classes=params['n_classes']).to(params['device'])\n        elif params['network'] == 'simplecnn':\n            model = SimpleCNN3D(n_classes=params['n_classes']).to(params['device'])\n        else:\n            raise ValueError(\"Unknown network type specified in\", params['network'])\n\n        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n    \n        # Variables\n        train_losses = []\n        val_losses = []\n        val_accuracies = []\n\n        best_accuracy = -float('inf')\n        best_epoch = -1\n        best_model_path = None\n\n        # Loop over epochs\n        for epoch in range(params['epochs']):\n            train_loss = train(train_loader, model, params['criterion'], optimizer, params['device'])\n            val_loss, val_accuracy = validate(val_loader, model, params['criterion'], params['device'], params['task'])\n\n            print(f\"Epoch {epoch+1}/{params['epochs']} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n\n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            val_accuracies.append(val_accuracy)\n\n            checkpoint_name = f\"best_model_fold{fold+1}_epoch{epoch+1}_{params['group1']}_vs_{params['group2']}.pt\"\n            full_path = os.path.join(checkpoints_dir, checkpoint_name)\n\n            if val_accuracy > best_accuracy:\n                best_accuracy = val_accuracy\n                best_epoch = epoch + 1\n                best_model_path = full_path\n                torch.save({\n                    'epoch': best_epoch,\n                    'state_dict': model.state_dict(),\n                    'optimizer_state': optimizer.state_dict(),\n                    'val_accuracy': best_accuracy,\n                    'val_loss': val_loss\n                }, best_model_path)\n                \n\n        # Log the best model for this fold\n        if best_model_path:\n            best_model_paths.append({\n                'fold': fold+1,\n                'model_path': best_model_path,\n                'best_accuracy': best_accuracy,\n                'best_epoch': best_epoch\n            })\n\n        # Save for plotting\n        plot_losses_and_accuracy(train_losses, val_losses, val_accuracies)\n        plot_losses_only(train_losses, val_losses)\n\n    return mbest_model_paths","metadata":{"_uuid":"66ab0210-bd10-408d-8c5f-0138c73e0865","_cell_guid":"c807ac98-646e-43cb-bc22-a5b935db1328","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{"_uuid":"57dcf171-266a-4124-91d3-7f25eddda102","_cell_guid":"66a3790c-90bf-4022-95db-dfa02f7b3aa4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def select_best_model_among_folds(best_model_paths):\n    \"\"\"\n    Selects the fold with the highest validation accuracy.\n    Returns the dictionary with model_path and metrics.\n    \"\"\"\n    best_entry = max(best_model_paths, key=lambda x: x['best_accuracy'])\n\n    print(\"\\n--- Best fold summary ---\")\n    print(f\"Fold number : {best_entry['fold']}\")\n    print(f\"Best Epoch  : {best_entry['best_epoch']}\")\n    print(f\"Best Accuracy: {best_entry['best_accuracy']:.4f}\")\n    print(f\"Model path  : {best_entry['model_path']}\\n\")\n\n    return best_entry","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(df_test, model_path, path_fcmaps, params):\n    test_dataset = FCDataset(path_fcmaps, df_test, params['label_column'], params['task'])\n    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n\n    if params['network'] == 'resnet':\n        model = ResNet3D(n_classes=params['n_classes']).to(params['device'])\n    elif params['network'] == 'simplecnn':\n        model = SimpleCNN3D(n_classes=params['n_classes']).to(params['device'])\n    else:\n        raise ValueError(\"Unknown network type specified in params['network']\")\n\n    # Load checkpoint\n    checkpoint = torch.load(model_path, map_location=params['device'])\n    model.load_state_dict(checkpoint['state_dict'], weights_only=True)\n    model.eval()\n\n    # Predicting\n    y_true, y_pred = evaluate(model, test_loader, params['task'], params['device'])\n\n    return y_true, y_pred\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_performance_and_plots(y_true, y_pred, params):\n    # --- METRICS ---\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    try:\n        roc_auc = roc_auc_score(y_true, y_pred)\n    except ValueError:\n        roc_auc = float('nan')  # AUC not computable if only 1 class present\n\n    print(\"\\n--- Test Metrics ---\")\n    print(f\"Accuracy : {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall   : {recall:.4f}\")\n    print(f\"F1-score : {f1:.4f}\")\n    print(f\"ROC AUC  : {roc_auc:.4f}\")\n\n    # --- CONFUSION MATRIX ---\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n                xticklabels=[params['group1'], params['group2']],\n                yticklabels=[params['group1'], params['group2']])\n    plt.title(\"Test Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n    # --- ROC CURVE ---\n    if params['task'] == 'classification':\n        fpr, tpr, _ = roc_curve(y_true, y_pred)\n        plt.figure(figsize=(6, 6))\n        plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n        plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'roc_auc': roc_auc\n    }","metadata":{"_uuid":"8344a777-9f96-479a-89f1-8eb686cbdee1","_cell_guid":"e3a9c4d9-bb3f-4b18-9140-674b62d753ff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"if params['use_cross_val']:\n    # ----- CROSS-VALIDATION -----\n    best_model_paths = train_model_kfold(df_train, path_fcmaps_augmented, path_fcmaps, params)\n    best_model_entry = select_best_model_among_folds(best_model_paths)\n    \n    best_model_path = best_model_entry['model_path']\n\nelse:\n    # ----- NO CROSS-VALIDATION -----\n    best_model_path, train_losses, val_losses, val_accuracies = train_model(\n        df_train, df_val, path_fcmaps_augmented, path_fcmaps, params\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Testing\n","metadata":{}},{"cell_type":"code","source":"# Eval\ny_true, y_pred = test_model(df_test, best_model_path, path_fcmaps, params)\n\n# Metrics\nperformance = compute_performance_and_plots(y_true, y_pred, params)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Synthetic data","metadata":{"_uuid":"1925b2d5-f1e7-4127-a2da-f2778a476918","_cell_guid":"0faab8c2-2efc-4b71-b5c5-5d321b84df9c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"Synthetic data creation","metadata":{"_uuid":"74003561-39b9-46fa-ad73-55367c02187d","_cell_guid":"87122bfe-5c66-450e-86f9-d0f8dfd87e58","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def create_synthetic_data(n_samples=1500):\n    img_shape = (1, 91, 109, 91)\n    block_coords = (slice(30,50), slice(40,60), slice(30,50))\n\n    synthetic_data = np.random.normal(0, 1, (n_samples, *img_shape))\n    synthetic_labels = np.array([0]*(n_samples//2) + [1]*(n_samples//2))\n\n    for i in range(n_samples//2, n_samples):\n        synthetic_data[i, 0, block_coords[0], block_coords[1], block_coords[2]] += 5\n\n    return synthetic_data, synthetic_labels","metadata":{"_uuid":"05129251-6819-4c89-a6a2-960c45e9243f","_cell_guid":"029e0101-2ec5-4350-9121-53ab0a0cd748","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-05T15:09:09.921637Z","iopub.execute_input":"2025-05-05T15:09:09.922281Z","iopub.status.idle":"2025-05-05T15:09:51.202304Z","shell.execute_reply.started":"2025-05-05T15:09:09.922252Z","shell.execute_reply":"2025-05-05T15:09:51.201487Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Data shape: (1500, 1, 91, 109, 91), Labels shape: (1500,)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Class Dataset","metadata":{"_uuid":"663721d2-c3b6-424a-b56d-ea114993e3ec","_cell_guid":"d216f715-b88a-441c-b4ea-e4fc6d123db4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-05T09:59:49.460781Z","iopub.execute_input":"2025-05-05T09:59:49.461342Z","iopub.status.idle":"2025-05-05T09:59:50.424221Z","shell.execute_reply.started":"2025-05-05T09:59:49.461321Z","shell.execute_reply":"2025-05-05T09:59:50.423510Z"},"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"class SyntheticDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.data[idx], dtype=torch.float32)\n        y = torch.tensor(self.labels[idx], dtype=torch.long)\n        return x, y\n","metadata":{"_uuid":"014a8e60-5834-4c9e-b7c3-49ddb591763f","_cell_guid":"e3db5ffd-e9a8-4e93-906c-ef51ef1f3285","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-05T15:10:10.356353Z","iopub.execute_input":"2025-05-05T15:10:10.356633Z","iopub.status.idle":"2025-05-05T15:10:10.361254Z","shell.execute_reply.started":"2025-05-05T15:10:10.356611Z","shell.execute_reply":"2025-05-05T15:10:10.360676Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Train / Validation Split and Dataloaders","metadata":{"_uuid":"d37c395c-5dc6-4832-b27a-2aa7d97b5c24","_cell_guid":"43b92007-f4e2-4e26-8456-2df699ca2fce","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def split_and_create_loaders(synthetic_data, synthetic_labels, params):\n    X_train, X_test, y_train, y_test = train_test_split(\n        synthetic_data, synthetic_labels,\n        test_size=params['test_size'],\n        stratify=synthetic_labels,\n        random_state=42\n    )\n\n    if params['use_cross_val']:\n        X_train_final = X_train\n        y_train_final = y_train\n        X_val = None\n        y_val = None\n    else:\n        X_train_final, X_val, y_train_final, y_val = train_test_split(\n            X_train, y_train,\n            test_size=params['val_size'],\n            stratify=y_train,\n            random_state=42\n        )\n\n    return X_train_final, y_train_final, X_val, y_val, X_test, y_test","metadata":{"_uuid":"bb0f5e6b-2d5d-4acd-b2aa-19a00fb7613e","_cell_guid":"b8c338c0-6771-4a72-bbf2-a6246a1442d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-05T15:10:12.091069Z","iopub.execute_input":"2025-05-05T15:10:12.091336Z","iopub.status.idle":"2025-05-05T15:10:16.523102Z","shell.execute_reply.started":"2025-05-05T15:10:12.091315Z","shell.execute_reply":"2025-05-05T15:10:16.522400Z"}},"outputs":[{"name":"stdout","text":"Train samples: 1200\nValidation samples: 150\nTest samples: 150\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def run_synthetic_experiment():\n    print(\"ðŸ”Ž Starting synthetic experiment...\")\n\n    # Step 1: Create data\n    synthetic_data, synthetic_labels = create_synthetic_data(n_samples=1500)\n\n    # Step 2: Parameters\n    params = get_synthetic_params()\n\n    # Step 3: Split & loaders\n    X_train_final, y_train_final, X_val, y_val, X_test, y_test = split_and_create_loaders(\n        synthetic_data, synthetic_labels, params\n    )\n\n    # Step 4: Train\n    if params['use_cross_val']:\n        best_model_paths = train_model_kfold_synthetic(X_train_final, y_train_final, params)\n        best_model_entry = select_best_model_among_folds(best_model_paths)\n        best_model_path = best_model_entry['model_path']\n    else:\n        best_model_path, train_losses, val_losses, val_accuracies = train_model_synthetic(\n            X_train_final, y_train_final, X_val, y_val, params\n        )\n\n    # Step 5: Test\n    test_dataset = SyntheticDataset(X_test, y_test)\n    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n\n    y_true, y_pred = test_model_synthetic(test_loader, best_model_path, params)\n\n    # Step 6: Performance\n    performance = compute_performance_and_plots(y_true, y_pred, params)\n\n    print(\"Synthetic experiment completed.\")\n    return performance\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"performance = run_synthetic_experiment()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}